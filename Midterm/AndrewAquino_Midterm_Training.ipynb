{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_LwEzfFmLrn",
        "outputId": "c5a63b87-eb6b-4faa-f198-30aa590be3cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 44 images\n",
            "[0] Detected 48 corners successfully.\n",
            "[1] Detected 48 corners successfully.\n",
            "[2] Detected 48 corners successfully.\n",
            "[3] Detected 48 corners successfully.\n",
            "[4] Detected 48 corners successfully.\n",
            "[5] Detected 48 corners successfully.\n",
            "[6] Detected 48 corners successfully.\n",
            "[7] Detected 48 corners successfully.\n",
            "[8] Detected 48 corners successfully.\n",
            "[9] Detected 48 corners successfully.\n",
            "[10] Detected 48 corners successfully.\n",
            "[11] Detected 48 corners successfully.\n",
            "[12] Detected 48 corners successfully.\n",
            "[13] Detected 48 corners successfully.\n",
            "[14] Detected 48 corners successfully.\n",
            "[15] Detected 48 corners successfully.\n",
            "[16] Detected 48 corners successfully.\n",
            "[17] Detected 48 corners successfully.\n",
            "[18] Detected 48 corners successfully.\n",
            "[19] Detected 48 corners successfully.\n",
            "[20] Detected 48 corners successfully.\n",
            "[21] Detected 48 corners successfully.\n",
            "[23] Detected 48 corners successfully.\n",
            "[24] Detected 48 corners successfully.\n",
            "[25] Detected 48 corners successfully.\n",
            "[26] Detected 48 corners successfully.\n",
            "[27] Detected 48 corners successfully.\n",
            "[28] Detected 48 corners successfully.\n",
            "[29] Detected 48 corners successfully.\n",
            "[30] Detected 48 corners successfully.\n",
            "[31] Detected 48 corners successfully.\n",
            "[32] Detected 48 corners successfully.\n",
            "[33] Detected 48 corners successfully.\n",
            "[34] Detected 48 corners successfully.\n",
            "[35] Detected 48 corners successfully.\n",
            "[36] Detected 48 corners successfully.\n",
            "[39] Detected 48 corners successfully.\n",
            "[40] Detected 48 corners successfully.\n",
            "[42] Detected 48 corners successfully.\n",
            "[43] Detected 48 corners successfully.\n",
            "\n",
            "--- Starting Calibration with 40 valid views ---\n",
            "Initial K (DLT):\n",
            " [[411.79986113  -4.50201363 675.0455445 ]\n",
            " [  0.         422.65146504 477.47658187]\n",
            " [  0.           0.           1.        ]]\n",
            "\n",
            "Starting Non-Linear Refinement (Adam)\n",
            "Epoch 200: Current Loss = 1503.6401, Avg. Reprojection RMSE = 6.1312 pixels\n",
            "Epoch 400: Current Loss = 1031.7210, Avg. Reprojection RMSE = 5.0787 pixels\n",
            "Epoch 600: Current Loss = 778.2878, Avg. Reprojection RMSE = 4.4110 pixels\n",
            "Epoch 800: Current Loss = 599.3540, Avg. Reprojection RMSE = 3.8709 pixels\n",
            "Epoch 1000: Current Loss = 475.4328, Avg. Reprojection RMSE = 3.4476 pixels\n",
            "Epoch 1200: Current Loss = 392.9085, Avg. Reprojection RMSE = 3.1341 pixels\n",
            "Epoch 1400: Current Loss = 338.4228, Avg. Reprojection RMSE = 2.9087 pixels\n",
            "Epoch 1600: Current Loss = 301.2903, Avg. Reprojection RMSE = 2.7445 pixels\n",
            "Epoch 1800: Current Loss = 275.2146, Avg. Reprojection RMSE = 2.6230 pixels\n",
            "Epoch 2000: Current Loss = 256.2377, Avg. Reprojection RMSE = 2.5310 pixels\n",
            "Epoch 2200: Current Loss = 241.6556, Avg. Reprojection RMSE = 2.4579 pixels\n",
            "Epoch 2400: Current Loss = 229.8592, Avg. Reprojection RMSE = 2.3972 pixels\n",
            "Epoch 2600: Current Loss = 220.1021, Avg. Reprojection RMSE = 2.3458 pixels\n",
            "Epoch 2800: Current Loss = 212.1187, Avg. Reprojection RMSE = 2.3028 pixels\n",
            "Epoch 3000: Current Loss = 203.6055, Avg. Reprojection RMSE = 2.2561 pixels\n",
            "\n",
            "--- Final Optimized Parameters ---\n",
            "Optimized K:\n",
            " [[413.84361994  -2.82888733 672.80863498]\n",
            " [  0.         420.23272046 475.350429  ]\n",
            " [  0.           0.           1.        ]]\n",
            "Distortion coefficients (k1, k2, p1, p2, k3):\n",
            " [-0.12039542  0.01538792  0.00524553 -0.00146859 -0.00086097]\n",
            "\n",
            "Final Average RMSE: 2.0389 pixels\n",
            "Calibration successful! \n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Andrew Aquino Midterm take home Exam training set \n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# Added these warning filtering so that it wouldnt clutter my console\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "#this defines the number of squares in the rows and columns of the patterns\n",
        "ROWS = 6\n",
        "COLS = 8\n",
        "SQUARE_SIZE = 1.0  #initally I thought eh square size was necceasry\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DTYPE = torch.float64\n",
        "CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "#these three functions helped with taking in the checker board from the images\n",
        "# and detect the corners for the calibartion\n",
        "def make_checkerboard_points(rows=ROWS, cols=COLS, size=SQUARE_SIZE):\n",
        "\n",
        "    objp = np.zeros((rows * cols, 3), dtype=np.float64)\n",
        "    objp[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2) * size\n",
        "    return objp\n",
        "\n",
        "def load_image_from_bytes(entry):\n",
        "\n",
        "    b = entry['bytes'] if isinstance(entry, dict) and 'bytes' in entry else entry\n",
        "\n",
        "    if isinstance(b, bytes):\n",
        "        return np.array(Image.open(io.BytesIO(b)).convert('L'))\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    if isinstance(entry, str):\n",
        "         return cv2.imread(entry, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    return None\n",
        "\n",
        "#I attempted to do this manually and had no luck so I had to use OpenCV to detect the corners\n",
        "def detect_corners_opencv(gray_img):\n",
        "    \"\"\"Detects and refines checkerboard corners.\"\"\"\n",
        "    if gray_img is None:\n",
        "      return None\n",
        "\n",
        "    # Corner detection pre-processing\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    enhanced_img = clahe.apply(gray_img)\n",
        "    blurred_img = cv2.GaussianBlur(enhanced_img, (5, 5), 0)\n",
        "\n",
        "    # Detection flags needed this for the wide angle images for testing\n",
        "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_CLUSTERING\n",
        "\n",
        "    ret, corners = cv2.findChessboardCorners(blurred_img, (COLS, ROWS), None, flags=flags)\n",
        "    if not ret:\n",
        "      return None\n",
        "\n",
        "    corners_subpix = cv2.cornerSubPix(gray_img, corners, (11, 11), (-1, -1), CRITERIA)\n",
        "    return corners_subpix.reshape(-1, 2)\n",
        "\n",
        "\n",
        "#These functions are the for the DLT Calibration\n",
        "#This function will normalize the points\n",
        "def normalize_points_2d(points):\n",
        "    pts = np.asarray(points)\n",
        "    mean = pts.mean(axis=0) #mean\n",
        "    std = pts.std(axis=0) #standard deviation\n",
        "    s = np.sqrt(2) / (np.mean(std) + 1e-12) #scaling factor for average distance\n",
        "    T = np.array([[s, 0, -s*mean[0]], [0, s, -s*mean[1]], [0, 0, 1]]) #standard 3x3 Transformation matrix\n",
        "    pts_h = np.column_stack([pts, np.ones(len(pts))]).T\n",
        "    pts_n = (T @ pts_h).T[:, :2]\n",
        "    return pts_n, T\n",
        "\n",
        "#this function will estimate the homography matrix between two sets of 2D Points\n",
        "def estimate_homography_dlt(obj_pts_2d, img_pts):\n",
        "    \"\"\"Estimates Homography H using DLT with normalization.\"\"\"\n",
        "    obj_n, To = normalize_points_2d(obj_pts_2d)\n",
        "    img_n, Ti = normalize_points_2d(img_pts)\n",
        "    A = [] #this is to contruct the matrix A based on the DLT Equation\n",
        "    for (X, Y), (x, y) in zip(obj_n, img_n):\n",
        "        A.append([-X, -Y, -1, 0, 0, 0, x*X, x*Y, x])\n",
        "        A.append([0, 0, 0, -X, -Y, -1, y*X, y*Y, y])\n",
        "    A = np.array(A, dtype=np.float64)\n",
        "    _, _, Vt = np.linalg.svd(A)#make changes to the last column\n",
        "    h = Vt[-1, :].reshape(3, 3)\n",
        "    H = np.linalg.inv(Ti) @ h @ To\n",
        "    return H / H[2, 2]\n",
        "\n",
        "#this estimates the instinsic matix K or Zhangs method\n",
        "def estimate_intrinsics_from_homographies(H_list):\n",
        "    def v_ij(H, i, j):\n",
        "        # vector V (6x1)\n",
        "        return np.array([H[0, i]*H[0, j], H[0, i]*H[1, j] + H[1, i]*H[0, j], H[1, i]*H[1, j],\n",
        "                         H[2, i]*H[0, j] + H[0, i]*H[2, j], H[2, i]*H[1, j] + H[1, i]*H[2, j], H[2, i]*H[2, j]])\n",
        "\n",
        "    V = []\n",
        "    for H in H_list:\n",
        "        H /= H[2, 2] #normaliztion\n",
        "        V.append(v_ij(H, 0, 1))\n",
        "        V.append(v_ij(H, 0, 0) - v_ij(H, 1, 1))\n",
        "\n",
        "    _, _, Vt = np.linalg.svd(np.vstack(V))\n",
        "    b = Vt[-1, :]\n",
        "    B11, B12, B22, B13, B23, B33 = b #extract the elements of the symmetrix matrix\n",
        "\n",
        "    # getting the intrinsic parameters (alphta, beta, gamna, u0 and v0)\n",
        "    v0 = (B12*B13 - B11*B23) / (B11*B22 - B12**2)\n",
        "    lam = B33 - (B13**2 + v0*(B12*B13 - B11*B23)) / B11\n",
        "    alpha = np.sqrt(np.abs(lam / B11))\n",
        "    beta = np.sqrt(np.abs(lam*B11 / (B11*B22 - B12**2)))\n",
        "    gamma = -B12*alpha**2*beta / lam\n",
        "    u0 = gamma*v0 / beta - B13*alpha**2 / lam\n",
        "\n",
        "    return np.array([[alpha, gamma, u0], [0.0, beta, v0], [0.0, 0.0, 1.0]])\n",
        "\n",
        "#then lastly this computs the rotation and translation matrix\n",
        "def extrinsic_from_homography(H, K):\n",
        "    Kinv = np.linalg.inv(K)\n",
        "    h1, h2, h3 = H[:, 0], H[:, 1], H[:, 2]\n",
        "    lam = 1 / np.linalg.norm(Kinv @ h1)\n",
        "\n",
        "    #the parameters for the Rotation matrix\n",
        "    r1, r2 = lam * (Kinv @ h1), lam * (Kinv @ h2)\n",
        "    r3 = np.cross(r1, r2)\n",
        "    t = lam * (Kinv @ h3)\n",
        "\n",
        "\n",
        "    R = np.column_stack([r1, r2, r3]) #inital rotation matrix\n",
        "    U, _, Vt = np.linalg.svd(R) #want to find the nearest orthogonalk matrix to R\n",
        "    R = U @ Vt\n",
        "\n",
        "    # this is just Rodrigues formula\n",
        "    theta = np.arccos(np.clip((np.trace(R) - 1) / 2, -1.0, 1.0)) #calculate the angle of rotation\n",
        "    if abs(theta) < 1e-8:\n",
        "      return np.zeros(3), t #if no rotation happens\n",
        "\n",
        "    sin_theta = np.sin(theta)\n",
        "    if abs(sin_theta) < 1e-8: #samething here , if no rotation happens\n",
        "      return np.zeros(3), t\n",
        "\n",
        "    #putting everything together and scaling everything by the calculated theta\n",
        "    r_vec = theta * np.array([R[2, 1] - R[1, 2], R[0, 2] - R[2, 0], R[1, 0] - R[0, 1]]) / (2*sin_theta)\n",
        "    return r_vec, t\n",
        "\n",
        "#this where I used Pytorch which would later be used for optimization\n",
        "def project_points_torch(obj_pts, rvec, tvec, K, dist_coeffs):\n",
        "    #just making sure everything is a Tensor\n",
        "    if not isinstance(obj_pts, torch.Tensor):\n",
        "        obj_pts = torch.tensor(obj_pts, dtype=rvec.dtype, device=rvec.device)\n",
        "\n",
        "    #computing the Rodrigues Formula, same as before but with tensors\n",
        "    theta = torch.norm(rvec)\n",
        "    #this is if there is no rotation\n",
        "    if theta.item() < 1e-12:\n",
        "        R = torch.eye(3, device=DEVICE, dtype=DTYPE)\n",
        "    else:\n",
        "        k = rvec / theta\n",
        "        K_skew = torch.zeros(3, 3, dtype=DTYPE, device=DEVICE)\n",
        "        K_skew[0, 1], K_skew[0, 2] = -k[2], k[1]\n",
        "        K_skew[1, 0], K_skew[1, 2] = k[2], -k[0]\n",
        "        K_skew[2, 0], K_skew[2, 1] = -k[1], k[0]\n",
        "        I = torch.eye(3, device=DEVICE, dtype=DTYPE)\n",
        "        #rodrigues formula\n",
        "        R = I + torch.sin(theta) * K_skew + (1 - torch.cos(theta)) * (K_skew @ K_skew)\n",
        "\n",
        "    Pcam = (R @ obj_pts.T).T + tvec.unsqueeze(0)\n",
        "    X = Pcam[:, 0] / (Pcam[:, 2] + 1e-12)\n",
        "    Y = Pcam[:, 1] / (Pcam[:, 2] + 1e-12)\n",
        "\n",
        "    # applying distortion (radial and tangential)\n",
        "    r2 = X**2 + Y**2\n",
        "    k1, k2, p1, p2, k3 = dist_coeffs[0], dist_coeffs[1], dist_coeffs[2], dist_coeffs[3], dist_coeffs[4]\n",
        "    radial = 1 + k1*r2 + k2*r2**2 + k3*r2**3\n",
        "    x_dist = X*radial + 2*p1*X*Y + p2*(r2 + 2*X**2)\n",
        "    y_dist = Y*radial + p1*(r2 + 2*Y**2) + 2*p2*X*Y\n",
        "\n",
        "    # applying intrinsics\n",
        "    fx, skew, cx = K[0, 0], K[0, 1], K[0, 2]\n",
        "    fy, cy = K[1, 1], K[1, 2]\n",
        "    u = fx*x_dist + skew*y_dist + cx\n",
        "    v = fy*y_dist + cy\n",
        "\n",
        "    return torch.stack([u, v], dim=1)\n",
        "\n",
        "#this function calls the one at the top of the script to helpfind the checkboard corners\n",
        "def build_image_points_list(df):\n",
        "    img_pts_list, objp = [], make_checkerboard_points()\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        gray = load_image_from_bytes(row.get('image', row.get('bytes')))\n",
        "        corners = detect_corners_opencv(gray)\n",
        "\n",
        "        if corners is not None and corners.shape[0] == ROWS * COLS:\n",
        "            img_pts_list.append(corners)\n",
        "            print(f\"[{idx}] Detected {corners.shape[0]} corners successfully.\")\n",
        "\n",
        "    return img_pts_list, objp[:, :2], objp\n",
        "\n",
        "#this is the main part of the code where is uses DLT/Zhangs method and\n",
        "#then uses PyTorch gradient optimization\n",
        "def calibrate_pipeline(df):\n",
        "    #DLT Calibration\n",
        "    img_pts_list, obj_pts_2d, obj_pts_3d = build_image_points_list(df)\n",
        "\n",
        "    print(f\"\\n--- Starting Calibration with {len(img_pts_list)} valid views ---\")\n",
        "\n",
        "    #DLT Initilization. Calculating the Homography, Intrinsic Matrix and Extrinisic Parameters\n",
        "    H_list = [estimate_homography_dlt(obj_pts_2d, pts) for pts in img_pts_list]\n",
        "    K_init = estimate_intrinsics_from_homographies(H_list)\n",
        "    extrinsics_init = [extrinsic_from_homography(H, K_init) for H in H_list]\n",
        "    print(\"Initial K (DLT):\\n\", K_init)\n",
        "\n",
        "    # this is the optimization using PyTorch\n",
        "    # make sure everything is a tensor first\n",
        "    obj_pts_t = torch.tensor(obj_pts_3d, dtype=DTYPE, device=DEVICE)\n",
        "    img_pts_all = [torch.tensor(pts, dtype=DTYPE, device=DEVICE) for pts in img_pts_list]\n",
        "\n",
        "    fx = torch.tensor(K_init[0, 0], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    fy = torch.tensor(K_init[1, 1], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    skew = torch.tensor(K_init[0, 1], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    cx = torch.tensor(K_init[0, 2], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    cy = torch.tensor(K_init[1, 2], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    dist = torch.zeros(5, dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    rvecs = [torch.tensor(r, dtype=DTYPE, device=DEVICE, requires_grad=True) for r, _ in extrinsics_init]\n",
        "    tvecs = [torch.tensor(t, dtype=DTYPE, device=DEVICE, requires_grad=True) for _, t in extrinsics_init]\n",
        "\n",
        "    #combining eveything that needs optimization\n",
        "    params = [fx, fy, skew, cx, cy, dist] + rvecs + tvecs\n",
        "    optimizer = torch.optim.Adam(params, lr=1e-3)\n",
        "\n",
        "    # This loop  is the optimization step, I used adam (gradient descent)\n",
        "    print(\"\\nStarting Non-Linear Refinement (Adam)\")\n",
        "    for epoch in range(3000):\n",
        "        optimizer.zero_grad() #to clear previous gradients\n",
        "        K_mat = torch.stack([\n",
        "            torch.stack([fx, skew, cx]),\n",
        "            torch.stack([torch.tensor(0.0, dtype=DTYPE, device=DEVICE), fy, cy]),\n",
        "            torch.stack([torch.tensor(0.0, dtype=DTYPE, device=DEVICE), torch.tensor(0.0, dtype=DTYPE, device=DEVICE), torch.tensor(1.0, dtype=DTYPE, device=DEVICE)])\n",
        "        ])\n",
        "\n",
        "        loss = torch.tensor(0.0, dtype=DTYPE, device=DEVICE)\n",
        "        #calculate the reporjection error like the opencv version\n",
        "        for rvec, tvec, img_pts_t in zip(rvecs, tvecs, img_pts_all):\n",
        "            proj = project_points_torch(obj_pts_t, rvec, tvec, K_mat, dist)\n",
        "            loss = loss + torch.mean((proj - img_pts_t)**2) #loss function Mean Squared Error\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #track progress as the code runs\n",
        "        if (epoch + 1) % 200 == 0:\n",
        "            rmse = torch.sqrt(loss / len(img_pts_all)).item()\n",
        "            print(f\"Epoch {epoch+1}: Current Loss = {loss:.4f}, Avg. Reprojection RMSE = {rmse:.4f} pixels\")\n",
        "\n",
        "    # Final Results\n",
        "    with torch.no_grad():\n",
        "        K_opt = K_mat.cpu().numpy()\n",
        "        dist_opt = dist.cpu().numpy()\n",
        "        final_errors = [torch.sqrt(torch.mean((project_points_torch(obj_pts_t, rvec, tvec, K_mat, dist) - img_pts_t)**2)).item()\n",
        "                        for rvec, tvec, img_pts_t in zip(rvecs, tvecs, img_pts_all)]\n",
        "\n",
        "    print(\"\\n--- Final Optimized Parameters ---\")\n",
        "    print(\"Optimized K:\\n\", K_opt)\n",
        "    print(\"Distortion coefficients (k1, k2, p1, p2, k3):\\n\", dist_opt)\n",
        "    print(f\"\\nFinal Average RMSE: {np.mean(final_errors):.4f} pixels\")\n",
        "    print(\"Calibration successful! \\n \\n\")\n",
        "\n",
        "    return None\n",
        "\n",
        "parquet_path = '/content/train-00000-of-00001.parquet'\n",
        "df = pd.read_parquet(parquet_path)\n",
        "print(f\"Loaded {len(df)} images\")\n",
        "calibrate_pipeline(df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
