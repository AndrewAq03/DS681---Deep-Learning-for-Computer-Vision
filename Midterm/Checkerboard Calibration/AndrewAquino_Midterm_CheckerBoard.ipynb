{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "W5SZ27hVpR1_",
        "outputId": "af1d192f-7524-44fe-b385-a3743bcd1cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Saved 14 images to my_calibration_images.parquet\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"images_to_parquet(\\\"/content/checkerboard_images\\\", \\\"my_calibration_images\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"pic14.jpg\",\n          \"pic9.jpg\",\n          \"pic8.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1b420da0-d009-4cf6-baab-8560dd5b4fbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic8.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic4.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic12.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic10.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic6.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic11.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic14.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic7.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic9.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic5.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
              "      <td>pic13.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b420da0-d009-4cf6-baab-8560dd5b4fbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b420da0-d009-4cf6-baab-8560dd5b4fbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b420da0-d009-4cf6-baab-8560dd5b4fbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-af77bf35-3b6d-405c-84ef-e945b49b834a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af77bf35-3b6d-405c-84ef-e945b49b834a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-af77bf35-3b6d-405c-84ef-e945b49b834a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                image   filename\n",
              "0   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic8.jpg\n",
              "1   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic3.jpg\n",
              "2   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic4.jpg\n",
              "3   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic2.jpg\n",
              "4   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  pic12.jpg\n",
              "5   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  pic10.jpg\n",
              "6   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic6.jpg\n",
              "7   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic1.jpg\n",
              "8   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  pic11.jpg\n",
              "9   {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  pic14.jpg\n",
              "10  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic7.jpg\n",
              "11  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic9.jpg\n",
              "12  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...   pic5.jpg\n",
              "13  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...  pic13.jpg"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#here I simply took the images that I took and converted it into the same dataframe as the training images\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def images_to_parquet(image_folder, output_parquet=\"images.parquet\"):\n",
        "    data = []\n",
        "\n",
        "    for filename in os.listdir(image_folder):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "            filepath = os.path.join(image_folder, filename)\n",
        "            with open(filepath, 'rb') as f:\n",
        "                img_bytes = f.read()\n",
        "            data.append({\n",
        "                \"image\": {\"bytes\": img_bytes, \"path\": filepath},\n",
        "                \"filename\": filename\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_parquet(output_parquet, index=False)\n",
        "    print(f\"âœ… Saved {len(df)} images to {output_parquet}\")\n",
        "    return df\n",
        "\n",
        "\n",
        "images_to_parquet(\"/content/checkerboard_images\", \"my_calibration_images.parquet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GofkMLfQWweQ",
        "outputId": "808d7ea6-63f5-477d-81fe-3f9e9389410a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 14 images\n",
            "[4] Detected 48 corners successfully.\n",
            "[12] Detected 48 corners successfully.\n",
            "\n",
            "--- Starting Calibration with 2 valid views ---\n",
            "Initial K (DLT):\n",
            " [[855.79818522  96.90466702 210.30484788]\n",
            " [  0.         863.00498405 112.08202518]\n",
            " [  0.           0.           1.        ]]\n",
            "\n",
            "Starting Non-Linear Refinement (Adam)\n",
            "Epoch 200: Current Loss = 1.2322, Avg. Reprojection RMSE = 0.7849 pixels\n",
            "Epoch 400: Current Loss = 1.1731, Avg. Reprojection RMSE = 0.7659 pixels\n",
            "Epoch 600: Current Loss = 1.1350, Avg. Reprojection RMSE = 0.7533 pixels\n",
            "Epoch 800: Current Loss = 1.1112, Avg. Reprojection RMSE = 0.7454 pixels\n",
            "Epoch 1000: Current Loss = 1.0958, Avg. Reprojection RMSE = 0.7402 pixels\n",
            "Epoch 1200: Current Loss = 1.0853, Avg. Reprojection RMSE = 0.7367 pixels\n",
            "Epoch 1400: Current Loss = 1.0774, Avg. Reprojection RMSE = 0.7340 pixels\n",
            "Epoch 1600: Current Loss = 1.0707, Avg. Reprojection RMSE = 0.7317 pixels\n",
            "Epoch 1800: Current Loss = 1.0661, Avg. Reprojection RMSE = 0.7301 pixels\n",
            "Epoch 2000: Current Loss = 1.0618, Avg. Reprojection RMSE = 0.7286 pixels\n",
            "Epoch 2200: Current Loss = 1.0674, Avg. Reprojection RMSE = 0.7306 pixels\n",
            "Epoch 2400: Current Loss = 1.0543, Avg. Reprojection RMSE = 0.7260 pixels\n",
            "Epoch 2600: Current Loss = 1.0509, Avg. Reprojection RMSE = 0.7249 pixels\n",
            "Epoch 2800: Current Loss = 1.0480, Avg. Reprojection RMSE = 0.7239 pixels\n",
            "Epoch 3000: Current Loss = 1.0454, Avg. Reprojection RMSE = 0.7230 pixels\n",
            "\n",
            "--- Final Optimized Parameters ---\n",
            "Optimized K:\n",
            " [[857.11909215  96.86574071 210.26580314]\n",
            " [  0.         862.33142852 111.99709262]\n",
            " [  0.           0.           1.        ]]\n",
            "Distortion coefficients (k1, k2, p1, p2, k3):\n",
            " [-0.02504038  0.17674676 -0.01606734 -0.02462939 -0.24299825]\n",
            "\n",
            "Final Average RMSE: 0.7227 pixels\n",
            "Calibration successful!\n"
          ]
        }
      ],
      "source": [
        "# Andrew Aquino Midterm take home Exam\n",
        "import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# Added these warning filtering so that it wouldnt clutter my console\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "#this defines the number of squares in the rows and columns of the patterns\n",
        "ROWS = 6\n",
        "COLS = 8\n",
        "SQUARE_SIZE = 1.0  #initally I thought eh square size was necceasry\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "DTYPE = torch.float64\n",
        "CRITERIA = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "#these three functions helped with taking in the checker board from the images\n",
        "# and detect the corners for the calibartion\n",
        "def make_checkerboard_points(rows=ROWS, cols=COLS, size=SQUARE_SIZE):\n",
        "\n",
        "    objp = np.zeros((rows * cols, 3), dtype=np.float64)\n",
        "    objp[:, :2] = np.mgrid[0:cols, 0:rows].T.reshape(-1, 2) * size\n",
        "    return objp\n",
        "\n",
        "def load_image_from_bytes(entry):\n",
        "\n",
        "    b = entry['bytes'] if isinstance(entry, dict) and 'bytes' in entry else entry\n",
        "\n",
        "    if isinstance(b, bytes):\n",
        "        return np.array(Image.open(io.BytesIO(b)).convert('L'))\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    if isinstance(entry, str):\n",
        "         return cv2.imread(entry, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    return None\n",
        "\n",
        "#I attempted to do this manually and had no luck so I had to use OpenCV to detect the corners\n",
        "def detect_corners_opencv(gray_img):\n",
        "    \"\"\"Detects and refines checkerboard corners.\"\"\"\n",
        "    if gray_img is None:\n",
        "      return None\n",
        "\n",
        "    # Corner detection pre-processing\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    enhanced_img = clahe.apply(gray_img)\n",
        "    blurred_img = cv2.GaussianBlur(enhanced_img, (5, 5), 0)\n",
        "\n",
        "    # Detection flags needed this for the wide angle images for testing\n",
        "    flags = cv2.CALIB_CB_ADAPTIVE_THRESH | cv2.CALIB_CB_NORMALIZE_IMAGE | cv2.CALIB_CB_CLUSTERING\n",
        "\n",
        "    ret, corners = cv2.findChessboardCorners(blurred_img, (COLS, ROWS), None, flags=flags)\n",
        "    if not ret:\n",
        "      return None\n",
        "\n",
        "    corners_subpix = cv2.cornerSubPix(gray_img, corners, (11, 11), (-1, -1), CRITERIA)\n",
        "    return corners_subpix.reshape(-1, 2)\n",
        "\n",
        "\n",
        "#These functions are the for the DLT Calibration\n",
        "#This function will normalize the points\n",
        "def normalize_points_2d(points):\n",
        "    pts = np.asarray(points)\n",
        "    mean = pts.mean(axis=0) #mean\n",
        "    std = pts.std(axis=0) #standard deviation\n",
        "    s = np.sqrt(2) / (np.mean(std) + 1e-12) #scaling factor for average distance\n",
        "    T = np.array([[s, 0, -s*mean[0]], [0, s, -s*mean[1]], [0, 0, 1]]) #standard 3x3 Transformation matrix\n",
        "    pts_h = np.column_stack([pts, np.ones(len(pts))]).T\n",
        "    pts_n = (T @ pts_h).T[:, :2]\n",
        "    return pts_n, T\n",
        "\n",
        "#this function will estimate the homography matrix between two sets of 2D Points\n",
        "def estimate_homography_dlt(obj_pts_2d, img_pts):\n",
        "    \"\"\"Estimates Homography H using DLT with normalization.\"\"\"\n",
        "    obj_n, To = normalize_points_2d(obj_pts_2d)\n",
        "    img_n, Ti = normalize_points_2d(img_pts)\n",
        "    A = [] #this is to contruct the matrix A based on the DLT Equation\n",
        "    for (X, Y), (x, y) in zip(obj_n, img_n):\n",
        "        A.append([-X, -Y, -1, 0, 0, 0, x*X, x*Y, x])\n",
        "        A.append([0, 0, 0, -X, -Y, -1, y*X, y*Y, y])\n",
        "    A = np.array(A, dtype=np.float64)\n",
        "    _, _, Vt = np.linalg.svd(A)#make changes to the last column\n",
        "    h = Vt[-1, :].reshape(3, 3)\n",
        "    H = np.linalg.inv(Ti) @ h @ To\n",
        "    return H / H[2, 2]\n",
        "\n",
        "#this estimates the instinsic matix K or Zhangs method\n",
        "def estimate_intrinsics_from_homographies(H_list):\n",
        "    def v_ij(H, i, j):\n",
        "        # vector V (6x1)\n",
        "        return np.array([H[0, i]*H[0, j], H[0, i]*H[1, j] + H[1, i]*H[0, j], H[1, i]*H[1, j],\n",
        "                         H[2, i]*H[0, j] + H[0, i]*H[2, j], H[2, i]*H[1, j] + H[1, i]*H[2, j], H[2, i]*H[2, j]])\n",
        "\n",
        "    V = []\n",
        "    for H in H_list:\n",
        "        H /= H[2, 2] #normaliztion\n",
        "        V.append(v_ij(H, 0, 1))\n",
        "        V.append(v_ij(H, 0, 0) - v_ij(H, 1, 1))\n",
        "\n",
        "    _, _, Vt = np.linalg.svd(np.vstack(V))\n",
        "    b = Vt[-1, :]\n",
        "    B11, B12, B22, B13, B23, B33 = b #extract the elements of the symmetrix matrix\n",
        "\n",
        "    # getting the intrinsic parameters (alphta, beta, gamna, u0 and v0)\n",
        "    v0 = (B12*B13 - B11*B23) / (B11*B22 - B12**2)\n",
        "    lam = B33 - (B13**2 + v0*(B12*B13 - B11*B23)) / B11\n",
        "    alpha = np.sqrt(np.abs(lam / B11))\n",
        "    beta = np.sqrt(np.abs(lam*B11 / (B11*B22 - B12**2)))\n",
        "    gamma = -B12*alpha**2*beta / lam\n",
        "    u0 = gamma*v0 / beta - B13*alpha**2 / lam\n",
        "\n",
        "    return np.array([[alpha, gamma, u0], [0.0, beta, v0], [0.0, 0.0, 1.0]])\n",
        "\n",
        "#then lastly this computs the rotation and translation matrix\n",
        "def extrinsic_from_homography(H, K):\n",
        "    Kinv = np.linalg.inv(K)\n",
        "    h1, h2, h3 = H[:, 0], H[:, 1], H[:, 2]\n",
        "    lam = 1 / np.linalg.norm(Kinv @ h1)\n",
        "\n",
        "    #the parameters for the Rotation matrix\n",
        "    r1, r2 = lam * (Kinv @ h1), lam * (Kinv @ h2)\n",
        "    r3 = np.cross(r1, r2)\n",
        "    t = lam * (Kinv @ h3)\n",
        "\n",
        "\n",
        "    R = np.column_stack([r1, r2, r3]) #inital rotation matrix\n",
        "    U, _, Vt = np.linalg.svd(R) #want to find the nearest orthogonalk matrix to R\n",
        "    R = U @ Vt\n",
        "\n",
        "    # this is just Rodrigues formula\n",
        "    theta = np.arccos(np.clip((np.trace(R) - 1) / 2, -1.0, 1.0)) #calculate the angle of rotation\n",
        "    if abs(theta) < 1e-8:\n",
        "      return np.zeros(3), t #if no rotation happens\n",
        "\n",
        "    sin_theta = np.sin(theta)\n",
        "    if abs(sin_theta) < 1e-8: #samething here , if no rotation happens\n",
        "      return np.zeros(3), t\n",
        "\n",
        "    #putting everything together and scaling everything by the calculated theta\n",
        "    r_vec = theta * np.array([R[2, 1] - R[1, 2], R[0, 2] - R[2, 0], R[1, 0] - R[0, 1]]) / (2*sin_theta)\n",
        "    return r_vec, t\n",
        "\n",
        "#this where I used Pytorch which would later be used for optimization\n",
        "def project_points_torch(obj_pts, rvec, tvec, K, dist_coeffs):\n",
        "    #just making sure everything is a Tensor\n",
        "    if not isinstance(obj_pts, torch.Tensor):\n",
        "        obj_pts = torch.tensor(obj_pts, dtype=rvec.dtype, device=rvec.device)\n",
        "\n",
        "    #computing the Rodrigues Formula, same as before but with tensors\n",
        "    theta = torch.norm(rvec)\n",
        "    #this is if there is no rotation\n",
        "    if theta.item() < 1e-12:\n",
        "        R = torch.eye(3, device=DEVICE, dtype=DTYPE)\n",
        "    else:\n",
        "        k = rvec / theta\n",
        "        K_skew = torch.zeros(3, 3, dtype=DTYPE, device=DEVICE)\n",
        "        K_skew[0, 1], K_skew[0, 2] = -k[2], k[1]\n",
        "        K_skew[1, 0], K_skew[1, 2] = k[2], -k[0]\n",
        "        K_skew[2, 0], K_skew[2, 1] = -k[1], k[0]\n",
        "        I = torch.eye(3, device=DEVICE, dtype=DTYPE)\n",
        "        #rodrigues formula\n",
        "        R = I + torch.sin(theta) * K_skew + (1 - torch.cos(theta)) * (K_skew @ K_skew)\n",
        "\n",
        "    Pcam = (R @ obj_pts.T).T + tvec.unsqueeze(0)\n",
        "    X = Pcam[:, 0] / (Pcam[:, 2] + 1e-12)\n",
        "    Y = Pcam[:, 1] / (Pcam[:, 2] + 1e-12)\n",
        "\n",
        "    # applying distortion (radial and tangential)\n",
        "    r2 = X**2 + Y**2\n",
        "    k1, k2, p1, p2, k3 = dist_coeffs[0], dist_coeffs[1], dist_coeffs[2], dist_coeffs[3], dist_coeffs[4]\n",
        "    radial = 1 + k1*r2 + k2*r2**2 + k3*r2**3\n",
        "    x_dist = X*radial + 2*p1*X*Y + p2*(r2 + 2*X**2)\n",
        "    y_dist = Y*radial + p1*(r2 + 2*Y**2) + 2*p2*X*Y\n",
        "\n",
        "    # applying intrinsics\n",
        "    fx, skew, cx = K[0, 0], K[0, 1], K[0, 2]\n",
        "    fy, cy = K[1, 1], K[1, 2]\n",
        "    u = fx*x_dist + skew*y_dist + cx\n",
        "    v = fy*y_dist + cy\n",
        "\n",
        "    return torch.stack([u, v], dim=1)\n",
        "\n",
        "#this function calls the one at the top of the script to helpfind the checkboard corners\n",
        "def build_image_points_list(df):\n",
        "    img_pts_list, objp = [], make_checkerboard_points()\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        gray = load_image_from_bytes(row.get('image', row.get('bytes')))\n",
        "        corners = detect_corners_opencv(gray)\n",
        "\n",
        "        if corners is not None and corners.shape[0] == ROWS * COLS:\n",
        "            img_pts_list.append(corners)\n",
        "            print(f\"[{idx}] Detected {corners.shape[0]} corners successfully.\")\n",
        "\n",
        "    return img_pts_list, objp[:, :2], objp\n",
        "\n",
        "#this is the main part of the code where is uses DLT/Zhangs method and\n",
        "#then uses PyTorch gradient optimization\n",
        "def calibrate_pipeline(df):\n",
        "    #DLT Calibration\n",
        "    img_pts_list, obj_pts_2d, obj_pts_3d = build_image_points_list(df)\n",
        "\n",
        "    print(f\"\\n--- Starting Calibration with {len(img_pts_list)} valid views ---\")\n",
        "\n",
        "    #DLT Initilization. Calculating the Homography, Intrinsic Matrix and Extrinisic Parameters\n",
        "    H_list = [estimate_homography_dlt(obj_pts_2d, pts) for pts in img_pts_list]\n",
        "    K_init = estimate_intrinsics_from_homographies(H_list)\n",
        "    extrinsics_init = [extrinsic_from_homography(H, K_init) for H in H_list]\n",
        "    print(\"Initial K (DLT):\\n\", K_init)\n",
        "\n",
        "    # this is the optimization using PyTorch\n",
        "    # make sure everything is a tensor first\n",
        "    obj_pts_t = torch.tensor(obj_pts_3d, dtype=DTYPE, device=DEVICE)\n",
        "    img_pts_all = [torch.tensor(pts, dtype=DTYPE, device=DEVICE) for pts in img_pts_list]\n",
        "\n",
        "    fx = torch.tensor(K_init[0, 0], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    fy = torch.tensor(K_init[1, 1], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    skew = torch.tensor(K_init[0, 1], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    cx = torch.tensor(K_init[0, 2], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    cy = torch.tensor(K_init[1, 2], dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    dist = torch.zeros(5, dtype=DTYPE, device=DEVICE, requires_grad=True)\n",
        "    rvecs = [torch.tensor(r, dtype=DTYPE, device=DEVICE, requires_grad=True) for r, _ in extrinsics_init]\n",
        "    tvecs = [torch.tensor(t, dtype=DTYPE, device=DEVICE, requires_grad=True) for _, t in extrinsics_init]\n",
        "\n",
        "    #combining eveything that needs optimization\n",
        "    params = [fx, fy, skew, cx, cy, dist] + rvecs + tvecs\n",
        "    optimizer = torch.optim.Adam(params, lr=1e-3)\n",
        "\n",
        "    # This loop  is the optimization step, I used adam (gradient descent)\n",
        "    print(\"\\nStarting Non-Linear Refinement (Adam)\")\n",
        "    for epoch in range(3000):\n",
        "        optimizer.zero_grad() #to clear previous gradients\n",
        "        K_mat = torch.stack([\n",
        "            torch.stack([fx, skew, cx]),\n",
        "            torch.stack([torch.tensor(0.0, dtype=DTYPE, device=DEVICE), fy, cy]),\n",
        "            torch.stack([torch.tensor(0.0, dtype=DTYPE, device=DEVICE), torch.tensor(0.0, dtype=DTYPE, device=DEVICE), torch.tensor(1.0, dtype=DTYPE, device=DEVICE)])\n",
        "        ])\n",
        "\n",
        "        loss = torch.tensor(0.0, dtype=DTYPE, device=DEVICE)\n",
        "        #calculate the reporjection error like the opencv version\n",
        "        for rvec, tvec, img_pts_t in zip(rvecs, tvecs, img_pts_all):\n",
        "            proj = project_points_torch(obj_pts_t, rvec, tvec, K_mat, dist)\n",
        "            loss = loss + torch.mean((proj - img_pts_t)**2) #loss function Mean Squared Error\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #track progress as the code runs\n",
        "        if (epoch + 1) % 200 == 0:\n",
        "            rmse = torch.sqrt(loss / len(img_pts_all)).item()\n",
        "            print(f\"Epoch {epoch+1}: Current Loss = {loss:.4f}, Avg. Reprojection RMSE = {rmse:.4f} pixels\")\n",
        "\n",
        "    # Final Results\n",
        "    with torch.no_grad():\n",
        "        K_opt = K_mat.cpu().numpy()\n",
        "        dist_opt = dist.cpu().numpy()\n",
        "        final_errors = [torch.sqrt(torch.mean((project_points_torch(obj_pts_t, rvec, tvec, K_mat, dist) - img_pts_t)**2)).item()\n",
        "                        for rvec, tvec, img_pts_t in zip(rvecs, tvecs, img_pts_all)]\n",
        "\n",
        "    print(\"\\n--- Final Optimized Parameters ---\")\n",
        "    print(\"Optimized K:\\n\", K_opt)\n",
        "    print(\"Distortion coefficients (k1, k2, p1, p2, k3):\\n\", dist_opt)\n",
        "    print(f\"\\nFinal Average RMSE: {np.mean(final_errors):.4f} pixels\")\n",
        "    print(\"Calibration successful!\")\n",
        "\n",
        "    return None\n",
        "\n",
        "parquet_path = '/content/my_calibration_images.parquet'\n",
        "df = pd.read_parquet(parquet_path)\n",
        "print(f\"Loaded {len(df)} images\")\n",
        "calibrate_pipeline(df)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
